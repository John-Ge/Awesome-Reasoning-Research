---
layout: post
title: a post with image galleries
date: 2024-12-04 01:59:00
description: this is what included image galleries could look like
tags: formatting images
categories: sample-posts
thumbnail: assets/img/9.jpg
images:
  lightbox2: true
  photoswipe: true
  spotlight: true
  venobox: true
---



https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero

Takeaways:
1. Simple PPO alghorithm without simple rule-based reward model could be trained with scaled time and compute.
2. KL divergence is term and the reference model could be removed and this does harm the stability of training.
3. The diversity and scale of data is quite important for the training of the model.

The citation is presented inline like this: <d-cite key="gregor2015draw"></d-cite> (a number that displays more information on hover).
If you have an appendix, a bibliography is automatically created and populated in it.

